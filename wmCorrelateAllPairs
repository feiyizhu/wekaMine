#!/usr/bin/env groovy

/**
This version is for "single" models.  That is, models that are made on the full set of samples, and not
specially created for each pair. 
*/
import grapnel.util.*
import grapnel.weka.*
import jsc.datastructures.PairedData
import jsc.correlation.KendallCorrelation
import jsc.correlation.LinearCorrelation

err = System.err
rng = new Random()

// Get the command line options, print help if needed. 
options = ParseOptions(args)
rowRange = options.experimentRange


predictions = new DoubleTable(options.data,"\t")

// Make a list of jobs. 
if (options.experimentsPerJob){
	scriptFile = getClass().protectionDomain.codeSource.location.path	
	WekaMine.writeClusterJobList(args,predictions.rows(),options.experimentsPerJob,scriptFile)	
	System.exit(0)
}

rowNames = predictions.rowNames
rowName2Idx = [:]
rowNames.eachWithIndex{r,i->
	rowName2Idx[r] = i
}

println rowRange.getFrom()
println rowRange.getTo()

if (rowRange.getFrom() == -1){
	rowRange = (rowRange.getTo()..rowNames.size()-1)
}else{
	err.println rowRange
}
println "Fixed rowRange: "+rowRange

// Go through the rows computing kendall's tau for each pair of classifications...
//outputTable = new DoubleTable(rowNames as ArrayList,rowNames as ArrayList)
outputTable = new TwoDMap()
def corr
for(row1Idx in rowRange){
//rowNames.each{rowName->
	rowName = rowNames[row1Idx]
	err.print "Processing row $row1Idx $rowName..."
	rowNames.each{colName->
		//row1Idx = rowName2Idx[rowName]
		row2Idx = rowName2Idx[colName]
		row1 = predictions[row1Idx]
		row2 = predictions[row2Idx]
		
		if (options.omitMissingValues){
			(row1,row2) = omitMissingValues(options.omitMissingValues,row1,row2)
		}
		
		if (options.pearsons){
			// The noise is added because LinearCorrelation chokes if the two datasets are
			// identical or invariante or something.... adding very tiny noise addresses this. 
			pd = new PairedData(addNoise(row1.asArray()),row2.asArray())					
			try{
				alg = new LinearCorrelation(pd)
				corr = alg.correlationCoeff(pd) 
			}catch(IllegalArgumentException e){				
				corr = 0.0 // call it uncorrelated if one of the columns is invariant. 
			}catch(Exception e){
				println "Exception: "+e
			}
		}else{
			pd = new PairedData(row1.asArray(),row2.asArray())							
			alg = new KendallCorrelation(pd)
			corr = alg.getR()
			sig = alg.getSP()
		}
		if (corr == Double.NaN) corr = 0.0 
		
		if (options.zeroSignificance){
			//err.println "$sig  ${options.zeroSignificance}  sig>=zs: ${sig >= options.zeroSignificance}"
			if (sig >= options.zeroSignificance){
				outputTable[rowName][colName] = corr
			}else{
				outputTable[rowName][colName] = 0
			}
		}else{				
			outputTable[rowName][colName] = corr
		}
		//err.print "."
	}
	err.println "done."
}

outFileName = options.outFileRoot + "${rowRange.from}_${rowRange.to}"
//err.println "filename: $outFileName"

//lines = outputTable.getLines("\t",nulVal = "null",heading=true)
//outFile = new File(outFileName)
//lines.each{
//	outFile << it
//	outFile << "\n"
//}
//outputTable.writeTable(outFileName,"\t","null")
//println outputTable
outFile = new File(outFileName)
outputTable.writeTable(outFile,"\t","null"){
	it
}


def addNoise(vals){
	def newvals = vals.collect{
		it + (rng.nextInt(4)*0.0001)
	}
	return(newvals as double[])
}

/***
* if either row1 or row2 contain missing values at a position, don't include that 
* value in the correlation. 
*/ 
def omitMissingValues(missingValue,row1,row2){
	def newrow1 = []
	def newrow2 = []
	
	for(int i in 0..<row1.size()){
		if ((row1[i] != missingValue) && (row2[i] != missingValue)){
			newrow1 << row1[i]
			newrow2 << row2[i]
		}				
	}
	rrow1 = new DoubleVector(newrow1)
	rrow2 = new DoubleVector(newrow2)
	
	return([rrow1,rrow2])
}

/****************************************************
* Parse the command line options, checking validity, printing help if needed. 
*/ 
def ParseOptions(args){
	parser = new Parser(description: '''
Cross correlate rows of table.  That is, compute kendalls tau for rows x rows table cells. 
Input is a models x samples file. 
Output is a models x models file.

Note that the output of wmCrossClassify includes lots of extra information. This must be
converted to a simple file of confidences with wmSelectAttributeValence
	''');

	parser.with{

	  required 'd','data', [description: 'Data file in models (row) by samples (col) format.']
		required 'o','outFileRoot', [description: 'Root file name for output.']
	  optional 'r','experimentRange',[default: "0,-1", description: 'Range of experiments to run (e.g. -r 54,67, mainly for cluster splits)',
			// Convert it to a proper range. Default is all inclusive range. 
			validate:{								
		 		experimentStart = (it.split(","))[0] as int
		 		experimentEnd = (it.split(","))[1] as int 
			  range = (experimentStart..experimentEnd)
				return(range)
			}]	
		
		optional 'O','omitMissingValues',[description: "Will any pairs where one or both members contain this 'missing value' value.",
		validate:{
			it as double
		}]
		
		optional 'z','zeroSignificance',[description: 'Zero all correlation values below this significance threshold.',
		validate:{
			it as double
		}
		]		
		optional 'k','experimentsPerJob',[description: 'When specified as last option, wmSaveModel does not run but instead outputs a list of wmSaveModel commands, k experiments each, for the cluster.']
		flag 'P','pearsons',[default:false,description: "Compute Pearsons correlation between all pairs (vs Kendall's tau the default)"]
	  flag 'h','help',[default:false,description: 'Print script help.']
	}

	def options
	try{
	  options = parser.parse(args)
	}catch(Exception e){
	  System.err << parser.usage
	  System.exit(1)
	}		
	return(options)
}
